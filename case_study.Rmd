---
title: "Using numerical solvers"
date: "`r Sys.Date()`"
author: "Juho Timonen and Ben Bales" 
output:
  html_document:
    toc: true
    theme: yeti
    highlight: textmate
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load, include=FALSE}
require(rstan)
```

## 1. Introduction

Assume we have a Bayesian model
\begin{equation}
p(\theta \mid \mathcal{D}) \propto p(\mathcal{D} \mid \theta) p(\theta)
\end{equation}
with data $\mathcal{D}$ and parameters $\theta$. Try as we might to make fitting
this model go fast in Stan, sometimes it just doesn't. There are numerous
reasons this might happen:

  1. Difficult to sample posterior geometry
  2. Inefficiently written Stan code
  3. Lots of data
  4. Use of heavy numerical methods to perform some calculations

The particular situation we want to discuss here is (4.), meaning you are happy
with your model, but it involves some implicitly defined functions or variables
which need to be solved using heavy numerical computations.

The above situation comes up relatively often when dealing with integrals and differential equations in Stan. Stan comes with a couple common ODE integrators (`integrate_ode_rk45`, `integrate_ode_bdf`, `integrate_ode_adams`) and one quadrature scheme (`integrate_1d`) in the language itself. These involve
error estimation and require defining a tolerance for the error. In general,
setting a lower tolerance means more accuracy but also more computation time.

If those prepackaged solutions with default tolerances are too slow, something
else must be done. The possibilities are to

  1. use the built-in methods with less strict tolerances 
  2. write a simpler custom quadrature or integrator by hand in the Stan
    model code.

These have in many cases been faster or more stable than the reference implementation in Stan. However, the question immediately becomes, how do I
know my method is accurate enough?

The goal of this case study is to figure out if your numerical method is biasing
the posterior inference of $\theta$, and, if possible use importance sampling to correct model predictions. This is using techniques from the papers
[@yao2018], [@vehtari2019], and
the `loo` software package (https://mc-stan.org/loo).

## 2. 1D Diffusion Example

### 2.1  Problem

First, let's start with a problem where Stan is slow. Let's pretend that we are modeling heat diffusion on a rod $x \in [0, L]$ as a partial differential equation
\begin{equation}
\frac{\partial u}{\partial t} = \kappa \cdot \frac{\partial^2 u}{\partial x^2}
\end{equation}
with boundary conditions
$$
u(t, x = 0) = 0 \\
u(t, x = L) = 1
$$
and initial heat distribution
\begin{equation}
u(t = 0, x) = 
\begin{cases}
0 & \text{ if } \hspace{0.5cm} 0 \leq x \leq \frac{L}{2} \\
1 & \text{ if } \hspace{0.5cm} \frac{L}{2} < x \leq 1
\end{cases}
\end{equation}
The thermal diffusivity parameter $\kappa$ is unknown. The goal is to eastimate it from noisy measurements of the concentration $u(t,x)$ at time $t = T$.

### 2.2 Simulating data
We generate test data using $\kappa_{true} = 0.25$. We can easily discretize the system using [method of lines](https://en.wikipedia.org/wiki/Method_of_lines) and generate some sample data in R:

```{r sim_functions}
# Function to solve u(t,x)
solve_u <- function(u_init, T_end, dt, dx) {
  u <- u_init
  for (t in seq(0, T_end, by = dt)) {
    u_new <- u
    for (i in 2:(length(u) - 1)) {
      u_new[i] <- dt * (u[i + 1] - 2 * u[i] + u[i - 1]) / (2 * dx) + u[i]
    }
    u <- u_new
  }
  return(u)
}

# Function to plot the solution
plot_u <- function(x, u_init, u_end, col1 = "gray30", col2 = "#198bff") {
  lwd <- 2
  plot(x, u_init, type = 'l', col = col1, main = 'Heat distribution on [0,L]', ylab = 'u(t,x)', xaxt = "n", lwd = lwd)
  lines(x, u_end, col = col2, lwd = lwd)
  legend(0.8, 0.4, legend = c("t = 0", "t = T"), col = c(col1, col2), lty = c(1,1), lwd = c(lwd, lwd))
  axis(1, at = c(0, 0.5, 1.0), labels = c("0", "L/2", "L"))
}
```


```{r simulate, fig.width = 6.5, fig.height = 4.5}
# Setup
L <- 1        # rod length
T_end <- 1    # time interval length
Kappa <- 0.25 # true value of kappa
dx <- 1e-2    # discretization step in x
dt <- 1e-4    # discretization step in t

# Define initial heat distribution u(t=0, x)
x_grid <- seq(0, 1, by = dx)
u_init <- x_grid > (0.5 * L)

# Solve u(t=T, x) and plot
u_end <- solve_u(u_init, T_end, dt, dx)
plot_u(x_grid, u_init, u_end)
```

Now, if you're familiar with diffusion equations you might say, 'Oh, you
fools, you've done a forward Euler method on a diffusion problem and you're
not even trying to control your error due to your timestep or your spatial
discretization.'

Since you are this far in the case study, we will admit, yes, this is a bad way
to solve the problem. We did it in a pinch because it was easier to do it
this way than worry about an adaptive timestep/adaptive meshsize method.
After all, we are solving a 1D diffusion. We can just make a finer
discretization or use smaller timesteps and see how the error between successive
approximations gets smaller.

But how should we check this in a model in Stan? The error in the solution from
using an approximation is important, but really the error in the posterior is
what matters. That leads to our first question

### 2.3 Is the Approximation Good Enough?

Assume we have a distribution $p_{true}(\theta)$ and $p_{approx}(\theta)$.

$p_{approx}$ is meant to approximate $p_{true}$. If they have the same support
then mathematically we can write expectations over $p_{true}$ as weighted
expectations over $p_{approx}$.

$$
E[f(\theta)] = \int f(\theta) p_{true}(\theta)\\
 = \int f(\theta) \frac{p_{true}(\theta)}{p_{approx}(\theta)}p_{approx}(\theta)d\theta
$$

If we're computing estimates with Monte Carlo, this means we replace
expectations over samples from our true distribution with weighted samples from
the approximate distribution.

$$
E[f(\theta)] \approx \frac{1}{N} \sum_n^N f(\theta_n) \\
\approx \frac{1}{N} \sum_n^N f(\theta_n) \frac{p_{true}(\theta)}{p_{approx}(\theta)}
$$
This is useful in MCMC when it is easier to sample from the approximation
than the truth. The ratios $\frac{p_{true}}{p_{approx}}$ are called importance
ratios. Perhaps unsurprisingly, this correction does not always work with
Monte Carlo. Indeed, if the difference in $p_{true}$ and $p_{approx}$ is too
great, then the importance ratios will be mostly things going to infinity or
zero.

In general, we can diagnose if the expectations will work by examing the
distribution of the importance weights by using the Pareto Smooth Importance
Sampling diagnostic. But first, let's write a Stan model

### 2.4 1D Diffusion in Stan

We define stan model.
```{r model}
model <- stan_model("diffusion.stan")
stan_data <- list(N = length(x_grid),
                  x = x_grid,
                  y = rnorm(u_end, 0.1),
                  L = L,
                  Tf = 0.1,
                  dt = 1e-3,
                  sigma = 0.1)
```
Hello, yes now we fit.

```{r fit, cache=TRUE}
fit <- sampling(model,
                data = stan_data,
                iter = 1000,
                chains = 4,
                cores = 4)
print(fit)
```

### 2.5 Correcting the Approximation
Heck.

## Computation environment

```{r session}
sessionInfo()
```

## References
